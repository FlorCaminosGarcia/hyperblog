name: Foundry Local
info:
  task: "Text Generation"
features:
  streaming: true
  structuredOutputs: false
  tokenCounting: false
  isEditable: false
  tools: true
  attachments:
    - type: text
      aitkEnhanced: true
      mimeTypes:
        - application/pdf
        - application/vnd.openxmlformats-officedocument.wordprocessingml.document
        - application/epub+zip
        - application/vnd.oasis.opendocument.text
        - application/rtf
        - text/csv
        - text/plain
        - text/html
        - application/json
        - application/vnd.openxmlformats-officedocument.presentationml.presentation
        - application/vnd.oasis.opendocument.presentation
        - text/javascript
        - text/css
        - application/x-httpd-php
        - application/x-sh
        - text/markdown
parameterSchema:
  enabled:
    - name: system_prompt
    - name: max_tokens
    # From Foundry Local Chat vscode extension
    - name: temperature
    - name: top_p
models:
  # The model's metadata is optional here and will merge with the ones returned from the API
  - name: Phi-4-cuda-gpu
    popular: 1
  - name: Phi-4-generic-gpu
    popular: 1
  - name: Phi-4-generic-cpu
    popular: 1
  - name: mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu
    popular: 2
  - name: mistralai-Mistral-7B-Instruct-v0-2-generic-gpu
    popular: 2
  - name: mistralai-Mistral-7B-Instruct-v0-2-generic-cpu
    popular: 2
